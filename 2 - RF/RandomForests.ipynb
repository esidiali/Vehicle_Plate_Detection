{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating and compiling the model...\n",
      "\n",
      "Loading EU images...\n",
      "\n",
      "Loading US images...\n",
      "\n",
      "Loading BR images...\n",
      "\n",
      " Loading data done\n",
      "\n",
      "Loading augmented images...\n",
      "\n",
      "Train-test split\n",
      "\n",
      "X_train shape :  (1839, 1766)\n",
      "y_train shape :  (1839, 4)\n",
      "X_test shape :  (460, 1766)\n",
      "y_test shape :  (460, 4)\n",
      "\n",
      "\n",
      "Training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from skimage.feature import hog\n",
    "\n",
    "new_shape = (64, 64)\n",
    "\n",
    "# Creating the model\n",
    "print(\"\\nCreating and compiling the model...\")\n",
    "m_depth = 10\n",
    "model = RandomForestRegressor(n_estimators=5000, n_jobs = -1, max_depth = m_depth)\n",
    "\n",
    "\n",
    "## function extract the box of the plate and read the image\n",
    "def process(input_file):\n",
    "    with open(input_file, 'r') as f:\n",
    "        a = f.readlines()[0]\n",
    "    a = a.split(\"\\t\")\n",
    "    name = a[0]\n",
    "    bbox = list(map(int, a[1:5]))\n",
    "    img = cv2.imread(input_file[:-4] + '.jpg')\n",
    "    return img, bbox\n",
    "\n",
    "## resize the image box\n",
    "def resize_im_box(image, box, new_shape):\n",
    "    resized_img = cv2.resize(image, new_shape)\n",
    "    \n",
    "    scale_y = new_shape[0] / image.shape[0]\n",
    "    scale_x = new_shape[1] / image.shape[1]\n",
    "    \n",
    "    resized_box = box.copy()\n",
    "    resized_box[0] = int(box[0]*scale_x)\n",
    "    resized_box[2] = int(box[2]*scale_x)\n",
    "    resized_box[1] = int(box[1]*scale_y)\n",
    "    resized_box[3] = int(box[3]*scale_y)\n",
    "    \n",
    "    return resized_img, resized_box\n",
    "\n",
    "### extract HOG features to improve the model\n",
    "def hog_feature(img_array, resize=(16,16)):\n",
    "    \"\"\"extract hog feature from an image.\n",
    "    Args:\n",
    "        img_array: an image array.\n",
    "        resize: size of the image for extracture.  \n",
    "    Return:\n",
    "    features:  a ndarray vector.      \n",
    "    \"\"\"\n",
    "    img = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "    bins = 9\n",
    "    cell_size = (8, 8)\n",
    "    cpb = (2, 2)\n",
    "    norm = \"L2\"\n",
    "    features = hog(img, orientations=bins, pixels_per_cell=cell_size,\n",
    "                        cells_per_block=cpb, block_norm=norm, transform_sqrt=True)\n",
    "    return features\n",
    "\n",
    "def make_feauture(img):\n",
    "    hog_f = hog_feature(img)\n",
    "    f = np.hstack([hog_f, np.array([img.shape[0], img.shape[1]])])\n",
    "    return f\n",
    "   \n",
    "\n",
    "#### Aply defined functions on the different datasets, we have\n",
    "print(\"\\nLoading EU images...\")\n",
    "eu_img_buffer = []\n",
    "eu_box_buffer = []\n",
    "\n",
    "for input_file in os.listdir(\"endtoend/eu/\"):\n",
    "    if input_file.endswith('.txt'):\n",
    "        img, box = process(\"endtoend/eu/\" + input_file)\n",
    "        img, box = resize_im_box(img, box, new_shape = new_shape)\n",
    "        eu_img_buffer.append(img)\n",
    "        eu_box_buffer.append(box)\n",
    "        \n",
    "us_img_buffer = []\n",
    "us_box_buffer = []\n",
    "\n",
    "print(\"\\nLoading US images...\")\n",
    "\n",
    "for input_file in os.listdir(\"endtoend/us/\"):\n",
    "    if input_file.endswith('.txt'):\n",
    "        img, box = process(\"endtoend/us/\" + input_file)\n",
    "        img, box = resize_im_box(img, box, new_shape = new_shape)\n",
    "        us_img_buffer.append(img)\n",
    "        us_box_buffer.append(box)\n",
    "\n",
    "print(\"\\nLoading BR images...\")\n",
    "\n",
    "br_img_buffer = []\n",
    "br_box_buffer = []\n",
    "\n",
    "for input_file in os.listdir(\"endtoend/br/\"):\n",
    "    if input_file.endswith('.txt'):\n",
    "        img, box = process(\"endtoend/br/\" + input_file)\n",
    "        img, box = resize_im_box(img, box, new_shape = new_shape)\n",
    "        br_img_buffer.append(img)\n",
    "        br_box_buffer.append(box)\n",
    "\n",
    "\n",
    "print(\"\\n Loading data done\")\n",
    "remove_for_vis = 5\n",
    "img_data_to_consider = eu_img_buffer[:-remove_for_vis] + us_img_buffer[:-remove_for_vis] + br_img_buffer[:-remove_for_vis]\n",
    "box_data_to_consider = eu_box_buffer[:-remove_for_vis] + us_box_buffer[:-remove_for_vis] + br_box_buffer[:-remove_for_vis]\n",
    "\n",
    "def process_line(line):\n",
    "    splits = line.split('\\t')\n",
    "    name = splits[0]\n",
    "    box = list(map(int, splits[1:-1]))\n",
    "    img = cv2.imread(\"augmented/\" + name)\n",
    "    return img, box\n",
    "    \n",
    "print(\"\\nLoading augmented images...\\n\") \n",
    "\n",
    "with open(\"augmented/augmented.txt\", \"r\") as my_file:\n",
    "    lines = my_file.readlines()\n",
    "    \n",
    "\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i]\n",
    "    img, box = process_line(line)\n",
    "    img, box = resize_im_box(img, box, new_shape = new_shape)\n",
    "    img_data_to_consider.append(img)\n",
    "    box_data_to_consider.append(box)\n",
    "\n",
    "#img_viz = eu_img_buffer[-remove_for_vis:] + us_img_buffer[-remove_for_vis:] + br_img_buffer[-remove_for_vis:]\n",
    "#box_viz = eu_box_buffer[-remove_for_vis:] + us_box_buffer[-remove_for_vis:] + br_box_buffer[-remove_for_vis:]\n",
    "\n",
    "img_data_to_consider = list(map(make_feauture, img_data_to_consider))\n",
    "\n",
    "print(\"Train-test split\")\n",
    "\n",
    "##### we have more than 13000 images (original and augmented), for a speed sake we gonna train and test only on 2300 images\n",
    "a= 11000 ### to remove from our set\n",
    "img_data_to_consider = img_data_to_consider[:-a]\n",
    "box_data_to_consider = box_data_to_consider[:-a]\n",
    "\n",
    "#### split to train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(img_data_to_consider), np.array(box_data_to_consider), \n",
    "                                                    test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(\"\\nX_train shape : \", X_train.shape)\n",
    "print(\"y_train shape : \", y_train.shape)\n",
    "print(\"X_test shape : \", X_test.shape)\n",
    "print(\"y_test shape : \", y_test.shape)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Training...\\n\")\n",
    "\n",
    "\n",
    "bsize = 256\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### create a function to make the report of the performances and export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model...\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "def make_report(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    r2_train = r2_score(y_true = y_train, y_pred = y_pred_train)\n",
    "    r2_test = r2_score(y_true = y_test, y_pred = y_pred_test)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_true = y_train, y_pred = y_pred_train)\n",
    "    mse_test = mean_squared_error(y_true = y_test, y_pred = y_pred_test)\n",
    "    \n",
    "    mae_train = mean_absolute_error(y_true = y_train, y_pred = y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_true = y_test, y_pred = y_pred_test)\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        data = {\n",
    "            \"R2\" : [r2_train, r2_test],\n",
    "            \"MSE\" : [mse_train, mse_test],\n",
    "            \"MAE\" : [mae_train, mae_test]\n",
    "        },\n",
    "        index = [\"train\", \"test\"]\n",
    "    )\n",
    "    \n",
    "\n",
    "print(\"Saving the model...\")\n",
    "\n",
    "try:\n",
    "    model.save(\"rfr_m_{}\".format(m_depth))\n",
    "except:\n",
    "    try:\n",
    "        with open(\"rfr_file_m_{}.pickle\", \"rb\") as rfr_file:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    \"rfr\":model,\n",
    "                    \"report\":make_report(y_train, y_pred_train, y_test, y_pred_test)\n",
    "                }, \n",
    "                rfr_file\n",
    "            )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.917673</td>\n",
       "      <td>9.285874</td>\n",
       "      <td>2.297585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.687397</td>\n",
       "      <td>37.811013</td>\n",
       "      <td>4.302360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             R2        MSE       MAE\n",
       "train  0.917673   9.285874  2.297585\n",
       "test   0.687397  37.811013  4.302360"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_report(y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
